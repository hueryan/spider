# Spider

## [第2章-基本库的使用](ch02/)

2.1-urllib的使用] [_](https://github.com/Python3WebSpider/UrllibTest)   

2.2-requests的使用 [_](https://github.com/Python3WebSpider/RequestsTest) 

2.3-正则表达式 [_](https://github.com/Python3WebSpider/RegexTest) 

2.4-httpx的使用 [_](https://github.com/Python3WebSpider/HttpxTest) `pip install "httpx[http2]"` 

2.5-基础爬虫案例实战 [_](https://github.com/Python3WebSpider/ScrapeSsr1)  exept [spider2.py](https://github.com/Python3WebSpider/ScrapeSsr1/blob/master/spider2.py) 

## [第3章-网页数据的解析爬取](ch03/)

3.1-XPath的使用 [_](https://github.com/Python3WebSpider/XPathTest) 

3.2-Beautiful Soup [_](https://github.com/Python3WebSpider/BeautifulSoupTest) 

3.3-pyquery的使用 [_](https://github.com/Python3WebSpider/PyQueryTest) 

3.4-parsel的使用 [_](https://github.com/Python3WebSpider/ParselTest) 

## [第 4 章-数据的存储](ch04/)

4.1-txt文本文件存储

4.2-JSON文件存储

4.3-CSV文件存储 [_](https://github.com/Python3WebSpider/FileStorageTest) 

4.4-MySQL存储 [_](https://github.com/Python3WebSpider/MySQLTest) 

4.5-MongoDB文档存储 [_](https://github.com/Python3WebSpider/MongoDBTest) 

4.6-Redis缓存存储

4.7-Elasticsearch搜索引擎存储 [_](https://github.com/Python3WebSpider/ElasticSearchTest) 

4.8-RabbitMQ的使用 [_](https://github.com/Python3WebSpider/RabbitMQTest) 
